{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glNS47fh5Tur",
        "outputId": "e7a61744-75ff-4831-ed6c-7ff7f29bc91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/breast-histopathology-images\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V6X7qN8N8NnP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "INPUT_DATASET = '/kaggle/input/breast-histopathology-images'\n",
        "BASE_PATH = '/kaggle/working/idc_dataset'\n",
        "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
        "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
        "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0kec5JJ8jML",
        "outputId": "567d699f-888b-4c0b-d56a-043794675d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building training set\n",
            "Building directory /kaggle/working/idc_dataset/training\n",
            "Building directory /kaggle/working/idc_dataset/training/0\n",
            "Building directory /kaggle/working/idc_dataset/training/1\n",
            "Building validation set\n",
            "Building directory /kaggle/working/idc_dataset/validation\n",
            "Building directory /kaggle/working/idc_dataset/validation/0\n",
            "Building directory /kaggle/working/idc_dataset/validation/1\n",
            "Building testing set\n",
            "Building directory /kaggle/working/idc_dataset/testing\n",
            "Building directory /kaggle/working/idc_dataset/testing/0\n",
            "Building directory /kaggle/working/idc_dataset/testing/1\n"
          ]
        }
      ],
      "source": [
        "from imutils import paths\n",
        "import random, shutil, os\n",
        "originalPaths = list(paths.list_images(INPUT_DATASET))\n",
        "random.seed(7)\n",
        "random.shuffle(originalPaths)\n",
        "index = int(len(originalPaths) * TRAIN_SPLIT)\n",
        "trainPaths = originalPaths[:index]\n",
        "testPaths = originalPaths[index:]\n",
        "index = int(len(trainPaths) * VAL_SPLIT)\n",
        "valPaths = trainPaths[:index]\n",
        "trainPaths = trainPaths[index:]\n",
        "datasets = [\n",
        "    (\"training\", trainPaths, TRAIN_PATH),\n",
        "    (\"validation\", valPaths, VAL_PATH),\n",
        "    (\"testing\", testPaths, TEST_PATH)\n",
        "]\n",
        "for (setType, originalPaths, baseOutput) in datasets:\n",
        "    print(f'Building {setType} set')\n",
        "    if not os.path.exists(baseOutput):\n",
        "        print(f'Building directory {baseOutput}')\n",
        "        os.makedirs(baseOutput)\n",
        "    for path in originalPaths:\n",
        "        filename = path.split(os.path.sep)[-1]\n",
        "        label = filename[-5:-4]\n",
        "        labelPath = os.path.sep.join([baseOutput, label])\n",
        "        if not os.path.exists(labelPath):\n",
        "            print(f'Building directory {labelPath}')\n",
        "            os.makedirs(labelPath)\n",
        "        newPath = os.path.sep.join([labelPath, filename])\n",
        "        shutil.copy2(path, newPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gEv8cGEnBuqM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "class CancerNet:\n",
        "    @staticmethod\n",
        "    def build(width,height,depth,classes):\n",
        "        model = tf.keras.models.Sequential()\n",
        "        channelDim=-1\n",
        "        if K.image_data_format()==\"channels_first\":\n",
        "            shape = (depth,height,width)\n",
        "            channelDim=1\n",
        "        else:\n",
        "            shape = (height, width, depth)\n",
        "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=shape))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "        model.add(tf.keras.layers.Dense(units=classes, activation='softmax'))\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bUqyWlLB-i3",
        "outputId": "968ec91e-2bfc-48d0-c332-eba80c9ca741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 42620 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory(VAL_PATH,\n",
        "                                                target_size = (64, 64),\n",
        "                                                batch_size = 32,\n",
        "                                                class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs5DSRzYCBse",
        "outputId": "5ded9841-be77-43c3-f8bc-2cfec0678a42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1332"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nba2AnojCJID",
        "outputId": "41b25834-c4fa-4295-c287-c3fb8afc03d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 255789 images belonging to 2 classes.\n",
            "Found 42620 images belonging to 2 classes.\n",
            "Found 99904 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "NUM_EPOCHS=4; INIT_LR=1e-2; BS=32\n",
        "\n",
        "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
        "lenTrain=len(trainPaths)\n",
        "lenVal=len(list(paths.list_images(VAL_PATH)))\n",
        "lenTest=len(list(paths.list_images(TEST_PATH)))\n",
        "\n",
        "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
        "trainLabels=to_categorical(trainLabels)\n",
        "classTotals=trainLabels.sum(axis=0)\n",
        "classWeight=classTotals.max()/classTotals\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.05,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
        "testAug=ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(48,48),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=BS)\n",
        "valGen = valAug.flow_from_directory(\n",
        "    VAL_PATH,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(48,48),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=BS)\n",
        "testGen = testAug.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(48,48),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=BS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnogWcDyCTdn",
        "outputId": "d8587cf8-6c9c-43f8-d806-172fd7d6b5d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2116s\u001b[0m 264ms/step - accuracy: 0.6929 - loss: 0.6445 - val_accuracy: 0.7108 - val_loss: 0.6028\n",
            "Epoch 2/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2004s\u001b[0m 251ms/step - accuracy: 0.7142 - loss: 0.6056 - val_accuracy: 0.7108 - val_loss: 0.5999\n",
            "Epoch 3/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2008s\u001b[0m 251ms/step - accuracy: 0.7165 - loss: 0.6006 - val_accuracy: 0.7108 - val_loss: 0.6024\n",
            "Epoch 4/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2011s\u001b[0m 252ms/step - accuracy: 0.7057 - loss: 0.6077 - val_accuracy: 0.7108 - val_loss: 0.6075\n",
            "Epoch 5/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2016s\u001b[0m 252ms/step - accuracy: 0.7130 - loss: 0.6017 - val_accuracy: 0.7108 - val_loss: 0.6024\n",
            "Epoch 6/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2005s\u001b[0m 251ms/step - accuracy: 0.7160 - loss: 0.5991 - val_accuracy: 0.7108 - val_loss: 0.6011\n",
            "Epoch 7/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 252ms/step - accuracy: 0.7143 - loss: 0.5996 - val_accuracy: 0.7108 - val_loss: 0.6028\n",
            "Epoch 8/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 252ms/step - accuracy: 0.7154 - loss: 0.5988 - val_accuracy: 0.7108 - val_loss: 0.6020\n",
            "Epoch 9/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2046s\u001b[0m 250ms/step - accuracy: 0.7122 - loss: 0.6011 - val_accuracy: 0.7108 - val_loss: 0.6083\n",
            "Epoch 10/10\n",
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1987s\u001b[0m 249ms/step - accuracy: 0.7138 - loss: 0.5995 - val_accuracy: 0.7108 - val_loss: 0.6003\n"
          ]
        }
      ],
      "source": [
        "model=CancerNet.build(width=48,height=48,depth=3,classes=2)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "M=model.fit(x=trainGen, validation_data = valGen, epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cOi-Xj_CUs1",
        "outputId": "896238db-99e9-4a56-cd84-a49a87837336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now evaluating the model\n",
            "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 58ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.83     71586\n",
            "           1       0.00      0.00      0.00     28318\n",
            "\n",
            "    accuracy                           0.72     99904\n",
            "   macro avg       0.36      0.50      0.42     99904\n",
            "weighted avg       0.51      0.72      0.60     99904\n",
            "\n",
            "[[71586     0]\n",
            " [28318     0]]\n",
            "Accuracy: 0.7165478859705318\n",
            "Specifity: 0.0\n",
            "Sensitivity: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Now evaluating the model\")\n",
        "testGen.reset()\n",
        "pred_indices=model.predict(testGen,steps=(lenTest//BS)+1)\n",
        "\n",
        "pred_indices=np.argmax(pred_indices,axis=1)\n",
        "\n",
        "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
        "\n",
        "cm=confusion_matrix(testGen.classes, pred_indices)\n",
        "total=sum(sum(cm))\n",
        "accuracy=(cm[0,0]+cm[1,1])/total\n",
        "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print(cm)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Specifity: {specificity}')\n",
        "print(f'Sensitivity: {sensitivity}')\n",
        "\n",
        "N = len(M.history[\"loss\"])\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0,N), M.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0,N), M.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0,N), M.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.legend(loc='lower left')\n",
        "plt.savefig('plot.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
